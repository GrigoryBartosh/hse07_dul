{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw32.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "336d4f27b78a43f5b925863e9d3b3027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b0a59af8daae4e2c9a92e4e4c35e0a56",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a6328c90a4754013a20442c7fa2eb98a",
              "IPY_MODEL_2c3e64874db744e89c051464948bb6f8"
            ]
          }
        },
        "b0a59af8daae4e2c9a92e4e4c35e0a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6328c90a4754013a20442c7fa2eb98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b51b3f700c9b4ed58b68f5fb645b35fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2b1ae0cd8754b44ab57355b000316d9"
          }
        },
        "2c3e64874db744e89c051464948bb6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f3148db9c1b448f9521c41a4631d2db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  4% 1/25 [01:38&lt;39:25, 98.55s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0986bd3e63da4d0db8bae4106d38e8f4"
          }
        },
        "b51b3f700c9b4ed58b68f5fb645b35fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2b1ae0cd8754b44ab57355b000316d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f3148db9c1b448f9521c41a4631d2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0986bd3e63da4d0db8bae4106d38e8f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GrigoryBartosh/hse07_dul/blob/hw3/hw32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ghpMUtD5mhry"
      },
      "source": [
        "# HW 3.2 High-dimensional data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zSgN3JaUqtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qRxFFBmUmhr1",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm.auto import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#PATH_DATA = os.path.join('data', 'hw3-q2.pkl')\n",
        "PATH_DATA = os.path.join('drive', 'My Drive', 'hw3-q2.pkl')\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7jId6n6smhr5",
        "colab": {}
      },
      "source": [
        "with open(PATH_DATA, 'rb') as file:\n",
        "    dataset = pickle.load(file)\n",
        "    \n",
        "xs_train = dataset['train']\n",
        "xs_val = dataset['valid']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4VFGYLJFmhr8",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "def collate_fn(xs):\n",
        "    xs = torch.tensor(xs, dtype=torch.float32)\n",
        "    xs = xs * 2 / 255 - 1\n",
        "    xs = xs.permute(0, 3, 1, 2)\n",
        "    return xs\n",
        "\n",
        "train_data_loader = data.DataLoader(\n",
        "    dataset=xs_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "val_data_loader = data.DataLoader(\n",
        "    dataset=xs_val,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WOrmZbKsmhr-"
      },
      "source": [
        "## Part A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lw2V56Ltmhr_",
        "colab": {}
      },
      "source": [
        "class GatedShortcutConnection(nn.Module):\n",
        "    def __init__(self, channels=128):\n",
        "        super(GatedShortcutConnection, self).__init__()\n",
        "                 \n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        return self.conv1(x) * self.sigmoid(self.conv2(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zAWlIByBmhsB",
        "colab": {}
      },
      "source": [
        "class ResidualStack(nn.Module):\n",
        "    def __init__(self, channels=64):\n",
        "        super(ResidualStack, self).__init__()\n",
        "                 \n",
        "        in_channels = channels * 4\n",
        "            \n",
        "        layers = []\n",
        "        for _ in range(5):\n",
        "            layers += [\n",
        "                nn.Conv2d(in_channels, channels, kernel_size=3, padding=1, bias=False),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(channels, channels * 2, kernel_size=3, padding=1, bias=False),\n",
        "                nn.ReLU(),\n",
        "                GatedShortcutConnection(channels=channels * 2),\n",
        "                nn.ReLU(),\n",
        "            ]\n",
        "            in_channels = channels * 2\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tUr96SARmhsD",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.channels = channels\n",
        "        \n",
        "        layers = [\n",
        "            nn.Conv2d(3, self.channels * 2, \n",
        "                      kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(self.channels * 2, self.channels * 4,\n",
        "                      kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(self.channels * 4, self.channels * 4,\n",
        "                      kernel_size=3, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            ResidualStack(self.channels),\n",
        "            nn.Conv2d(self.channels * 2, self.channels * 4,\n",
        "                      kernel_size=1)\n",
        "        ]\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.reshape(-1, 2, 2 * self.channels, 8, 8)\n",
        "        mu, log_var = x[:, 0], x[:, 1]\n",
        "        var = torch.exp(log_var)\n",
        "        return mu, var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "psEGJ8VhmhsG",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.channels = channels\n",
        "        \n",
        "        layers = [\n",
        "            nn.Conv2d(self.channels * 2, self.channels * 4,\n",
        "                      kernel_size=3, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            ResidualStack(self.channels),\n",
        "            nn.ConvTranspose2d(self.channels * 2, self.channels * 2,\n",
        "                               kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(self.channels * 2, 3 * 2,\n",
        "                               kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        ]\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "                 \n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.reshape(-1, 2, 3, 32, 32)\n",
        "        mu, log_var = x[:, 0], x[:, 1]\n",
        "        var = torch.exp(log_var)\n",
        "        return mu, var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WHpyKyqdmhsI",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, channels=64):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        self.channels = channels\n",
        "        \n",
        "        self.encoder = Encoder(channels)\n",
        "        self.decoder = Decoder(channels)\n",
        "        \n",
        "    def get_latent_size(self):\n",
        "        return [2 * self.channels, 8, 8]\n",
        "    \n",
        "    def reparameterize(self, mu, var):\n",
        "        eps = torch.randn_like(mu, device=device)\n",
        "        z = mu + eps * torch.sqrt(var)\n",
        "        return z\n",
        "            \n",
        "    def encode(self, x, training=True):\n",
        "        mu, var = self.encoder(x)\n",
        "        z = self.reparameterize(mu, var)\n",
        "        return (mu, var, z) if training else mu\n",
        "    \n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        mu_z, var_z, z = self.encode(x)\n",
        "        mu_x, var_x = self.decode(z)\n",
        "        return (mu_z, var_z), mu_x, var_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YOPktsUCmhsL",
        "colab": {}
      },
      "source": [
        "class MSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MSELoss, self).__init__()\n",
        "        \n",
        "    def forward(self, mu, var, x):\n",
        "        prob = -0.5 * (torch.log(np.pi * 2 * var) + (x - mu) ** 2 / var)\n",
        "        loss = -prob.mean()\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LrvA-gExmhsN",
        "colab": {}
      },
      "source": [
        "class KLLossStandard(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(KLLossStandard, self).__init__()\n",
        "        \n",
        "    def forward(self, mu, var):\n",
        "        kl_div = 1.0 + torch.log(var) - mu ** 2 - var\n",
        "        kl_div = -0.5 * kl_div\n",
        "        loss = kl_div.mean()\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wJTRcl1cmhsP",
        "colab": {}
      },
      "source": [
        "def train(model, criterion_mse, criterion_kl,\n",
        "          optimizer, scheduler, epochs):\n",
        "    losses_mse_train = []\n",
        "    losses_kl_train = []\n",
        "    losses_train = []\n",
        "    losses_mse_val = []\n",
        "    losses_kl_val = []\n",
        "    losses_val = []\n",
        "    for i in trange(epochs):\n",
        "        losses_mse = []\n",
        "        losses_kl = []\n",
        "        losses = []\n",
        "        model.train()\n",
        "        for xs in train_data_loader:\n",
        "            xs = xs.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            z_data, mu_x, var_x = model(xs)\n",
        "            \n",
        "            loss_mse = criterion_mse(mu_x, var_x, xs)\n",
        "            loss_kl = criterion_kl(*z_data)\n",
        "            loss = loss_mse + loss_kl\n",
        "\n",
        "            losses_mse.append(loss_mse.item())\n",
        "            losses_kl.append(loss_kl.item())\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        losses_mse_train.append(np.array(losses_mse).mean())\n",
        "        losses_kl_train.append(np.array(losses_kl).mean())\n",
        "        losses_train.append(np.array(losses).mean())\n",
        "\n",
        "        losses_mse = []\n",
        "        losses_kl = []\n",
        "        losses = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xs in val_data_loader:\n",
        "                xs = xs.to(device)\n",
        "\n",
        "                z_data, mu_x, var_x = model(xs)\n",
        "\n",
        "                loss_mse = criterion_mse(mu_x, var_x, xs)\n",
        "                loss_kl = criterion_kl(*z_data)\n",
        "                loss = loss_mse + loss_kl\n",
        "\n",
        "                losses_mse.append(loss_mse.item())\n",
        "                losses_kl.append(loss_kl.item())\n",
        "                losses.append(loss.item())\n",
        "\n",
        "        losses_mse_val.append(np.array(losses_mse).mean())\n",
        "        losses_kl_val.append(np.array(losses_kl).mean())\n",
        "        losses_val.append(np.array(losses).mean())\n",
        "        \n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "    plt.plot(range(epochs), losses_mse_train, label=\"train\")\n",
        "    plt.plot(range(epochs), losses_mse_val, label=\"val\")\n",
        "    plt.xlabel('epoch num')\n",
        "    plt.ylabel('loss mse')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(range(epochs), losses_kl_train, label=\"train\")\n",
        "    plt.plot(range(epochs), losses_kl_val, label=\"val\")\n",
        "    plt.xlabel('epoch num')\n",
        "    plt.ylabel('loss KL')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(range(epochs), losses_train, label=\"train\")\n",
        "    plt.plot(range(epochs), losses_val, label=\"val\")\n",
        "    plt.xlabel('epoch num')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RcnnLJhBmhsR",
        "colab": {}
      },
      "source": [
        "def show_interpolation(model, n=5, m=10):\n",
        "    sample_ids = list(range(n))\n",
        "    samples_a = xs_train[sample_ids]\n",
        "    samples_b = xs_train[sample_ids[-1:] + sample_ids[:-1]]\n",
        "    samples_a = collate_fn(samples_a).to(device)\n",
        "    samples_b = collate_fn(samples_b).to(device)\n",
        "    \n",
        "    images = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(n):\n",
        "            a, b = samples_a[i], samples_b[i]\n",
        "            za, zb = model.encode(a[None, :], training=False), model.encode(b[None, :], training=False)\n",
        "            for j in range(m):\n",
        "                x, _ = model.decode(za + (zb - za) * j / (m - 1))\n",
        "                x = x.permute(0, 2, 3, 1).cpu().numpy()[0]\n",
        "                images.append(x)\n",
        "            \n",
        "    images = np.array(images)\n",
        "    images = (images + 1) / 2\n",
        "    images = np.clip(images, 0, 1)\n",
        "    \n",
        "    f, axarr = plt.subplots(n, m)\n",
        "    f.set_figheight(15)\n",
        "    f.set_figwidth(15)\n",
        "    for i, img in enumerate(images):\n",
        "        axarr[n - 1 - i // m, i % m].imshow(img)\n",
        "        axarr[n - 1 - i // m, i % m].axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9FEm0nO9mhsT",
        "colab": {}
      },
      "source": [
        "def show_sampels(model, n=100):\n",
        "    z = torch.randn([n, *model.get_latent_size()]).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        images, _ = model.decode(z)\n",
        "        images = images.permute(0, 2, 3, 1).cpu().numpy()\n",
        "        \n",
        "    images = (images + 1) / 2\n",
        "    images = np.clip(images, 0, 1)\n",
        "    \n",
        "    n = int(np.ceil(np.sqrt(n)))\n",
        "    f, axarr = plt.subplots(n, n)\n",
        "    f.set_figheight(15)\n",
        "    f.set_figwidth(15)\n",
        "    for i, img in enumerate(images):\n",
        "        axarr[i // n, i % n].imshow(img)\n",
        "        axarr[i // n, i % n].axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gkfQcIe8mhsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "336d4f27b78a43f5b925863e9d3b3027",
            "b0a59af8daae4e2c9a92e4e4c35e0a56",
            "a6328c90a4754013a20442c7fa2eb98a",
            "2c3e64874db744e89c051464948bb6f8",
            "b51b3f700c9b4ed58b68f5fb645b35fc",
            "a2b1ae0cd8754b44ab57355b000316d9",
            "6f3148db9c1b448f9521c41a4631d2db",
            "0986bd3e63da4d0db8bae4106d38e8f4"
          ]
        },
        "outputId": "8478c57b-7b28-407c-cf22-8e9fe4a2066a"
      },
      "source": [
        "epochs = 25\n",
        "lr = 0.0002\n",
        "w_l2 = 0\n",
        "\n",
        "model = VAE(channels=64)\n",
        "model.to(device)\n",
        "\n",
        "criterion_mse = MSELoss()\n",
        "criterion_kl = KLLossStandard()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr, weight_decay=w_l2)\n",
        "\n",
        "train(model, criterion_mse, criterion_kl, optimizer, None, epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "336d4f27b78a43f5b925863e9d3b3027",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m81UYiaDmhsZ",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "show_interpolation(model, 10, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZPzXVf3Ymhsc",
        "colab": {}
      },
      "source": [
        "show_sampels(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TWSW5251mhse"
      },
      "source": [
        "## Part B VAE PixelCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnY1Nj7lUh3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskedConv2d(nn.Conv2d):\n",
        "    def __init__(self, mask_type, *args, **kwargs):\n",
        "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
        "        \n",
        "        self.register_buffer('mask', torch.ones_like(self.weight))\n",
        "        _, _, h, w = self.mask.size()\n",
        "        self.mask[:, :, h // 2, w // 2 + (mask_type == 'B'):] = 0\n",
        "        self.mask[:, :, h // 2 + 1:] = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.weight.data *= self.mask\n",
        "        return super(MaskedConv2d, self).forward(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwgZ7T70Uh3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskResBlock(nn.Module):\n",
        "    def __init__(self, h=128):\n",
        "        super(MaskResBlock, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(2 * h, h, 1),\n",
        "            nn.BatchNorm2d(h),\n",
        "            nn.ReLU(),\n",
        "            MaskedConv2d('B', h, h, 3, 1, 1),\n",
        "            nn.BatchNorm2d(h),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(h, 2 * h, 1),\n",
        "            nn.BatchNorm2d(2 * h)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x) + x\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FarScDHUh3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PixelCNN(nn.Module):\n",
        "    def __init__(self, h=128):\n",
        "        super(PixelCNN, self).__init__()\n",
        "        \n",
        "        layers = [MaskedConv2d('A', h, 2 * h, 3, 1, 1)]\n",
        "        layers += [MaskResBlock(h) for _ in range(3)]\n",
        "        layers += [nn.Conv2d(2 * h, 2 * h, kernel_size=1)]\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.reshape(-1, 2, x.shape[1] // 2, 8, 8)\n",
        "        mu, log_var = x[:, 0], x[:, 1]\n",
        "        var = torch.exp(log_var)\n",
        "        return mu, var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8yozjN6Uh3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAEPixelCNN(nn.Module):\n",
        "    def __init__(self, channels=64):\n",
        "        super(VAEPixelCNN, self).__init__()\n",
        "        \n",
        "        self.channels = channels\n",
        "        \n",
        "        self.encoder = Encoder(channels)\n",
        "        \n",
        "        self.pixel_cnn = PixelCNN(2 * channels)\n",
        "        \n",
        "        self.decoder = Decoder(channels)\n",
        "        \n",
        "    def get_latent_size(self):\n",
        "        return [2 * self.channels, 8, 8]\n",
        "    \n",
        "    def reparameterize(self, mu, var):\n",
        "        eps = torch.randn_like(mu, device=device)\n",
        "        z = mu + eps * torch.sqrt(var)\n",
        "        return z\n",
        "            \n",
        "    def encode(self, x, training=True):\n",
        "        mu_z1, var_z1 = self.encoder(x)\n",
        "        z = self.reparameterize(mu_z1, var_z1)\n",
        "        mu_z2, var_z2 = self.pixel_cnn(z)\n",
        "        return (mu_z1, var_z1, mu_z2, var_z2, z) if training else mu_z1\n",
        "    \n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        mu_z1, var_z1, mu_z2, var_z2, z = self.encode(x)\n",
        "        mu_x, var_x = self.decode(z)\n",
        "        return (mu_z1, var_z1, mu_z2, var_z2, z), mu_x, var_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzt8ge7OUh3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KLLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(KLLoss, self).__init__()\n",
        "        \n",
        "    def get_prob(self, mu, var, x):\n",
        "        return -0.5 * (torch.log(np.pi * 2 * var) + (x - mu) ** 2 / var)\n",
        "        \n",
        "    def forward(self, mu_z1, var_z1, mu_z2, var_z2, z):\n",
        "        p1 = self.get_prob(mu_z1, var_z1, z)\n",
        "        p2 = self.get_prob(mu_z2, var_z2, z)\n",
        "        loss = (p1 - p2).mean()\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzdlSCQ6Uh3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 25\n",
        "lr = 0.0002\n",
        "w_l2 = 0\n",
        "\n",
        "model = VAEPixelCNN(channels=64)\n",
        "model.to(device)\n",
        "\n",
        "criterion_mse = MSELoss()\n",
        "criterion_kl = KLLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr, weight_decay=w_l2)\n",
        "\n",
        "train(model, criterion_mse, criterion_kl, optimizer, None, epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHPHmqkYUh3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "show_interpolation(model, 10, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qbNa_reUh3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_sampels(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}