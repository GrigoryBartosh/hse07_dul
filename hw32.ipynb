{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GrigoryBartosh/hse07_dul/blob/hw3/hw32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghpMUtD5mhry"
   },
   "source": [
    "# HW 3.2 High-dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRxFFBmUmhr1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH_DATA = os.path.join('data', 'hw3-q2.pkl')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jId6n6smhr5"
   },
   "outputs": [],
   "source": [
    "with open(PATH_DATA, 'rb') as file:\n",
    "    dataset = pickle.load(file)\n",
    "    \n",
    "xs_train = dataset['train']\n",
    "xs_val = dataset['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4VFGYLJFmhr8"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def collate_fn(xs):\n",
    "    xs = torch.tensor(xs, dtype=torch.float32)\n",
    "    xs = xs * 2 / 255 - 1\n",
    "    xs = xs.permute(0, 3, 1, 2)\n",
    "    return xs\n",
    "\n",
    "train_data_loader = data.DataLoader(\n",
    "    dataset=xs_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "val_data_loader = data.DataLoader(\n",
    "    dataset=xs_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WOrmZbKsmhr-"
   },
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lw2V56Ltmhr_"
   },
   "outputs": [],
   "source": [
    "class GatedShortcutConnection(nn.Module):\n",
    "    def __init__(self, channels=128):\n",
    "        super(GatedShortcutConnection, self).__init__()\n",
    "                 \n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "                 \n",
    "    def forward(self, x):\n",
    "        return self.conv1(x) * self.sigmoid(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAWlIByBmhsB"
   },
   "outputs": [],
   "source": [
    "class ResidualStack(nn.Module):\n",
    "    def __init__(self, channels=64):\n",
    "        super(ResidualStack, self).__init__()\n",
    "                 \n",
    "        in_channels = channels * 4\n",
    "            \n",
    "        layers = []\n",
    "        for _ in range(5):\n",
    "            layers += [\n",
    "                nn.Conv2d(in_channels, channels, kernel_size=3, padding=1, bias=False),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(channels, channels * 2, kernel_size=3, padding=1, bias=False),\n",
    "                nn.ReLU(),\n",
    "                GatedShortcutConnection(channels=channels * 2),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "            in_channels = channels * 2\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "                 \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tUr96SARmhsD"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        \n",
    "        layers = [\n",
    "            nn.Conv2d(3, self.channels * 2, \n",
    "                      kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.channels * 2, self.channels * 4,\n",
    "                      kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.channels * 4, self.channels * 4,\n",
    "                      kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            ResidualStack(self.channels),\n",
    "            nn.Conv2d(self.channels * 2, self.channels * 4,\n",
    "                      kernel_size=1)\n",
    "        ]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "                 \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.reshape(-1, 2, 2 * self.channels, 8, 8)\n",
    "        mu, log_var = x[:, 0], x[:, 1]\n",
    "        var = torch.exp(log_var)\n",
    "        return mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psEGJ8VhmhsG"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        \n",
    "        layers = [\n",
    "            nn.Conv2d(self.channels * 2, self.channels * 4,\n",
    "                      kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            ResidualStack(self.channels),\n",
    "            nn.ConvTranspose2d(self.channels * 2, self.channels * 2,\n",
    "                               kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(self.channels * 2, 3 * 2,\n",
    "                               kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        ]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "                 \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.reshape(-1, 2, 3, 32, 32)\n",
    "        mu, log_var = x[:, 0], x[:, 1]\n",
    "        var = torch.exp(log_var)\n",
    "        return mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHpyKyqdmhsI"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, channels=64):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        \n",
    "        self.encoder = Encoder(channels)\n",
    "        self.decoder = Decoder(channels)\n",
    "        \n",
    "    def get_latent_size(self):\n",
    "        return [2 * self.channels, 8, 8]\n",
    "    \n",
    "    def reparameterize(self, mu, var):\n",
    "        eps = torch.randn_like(mu, device=device)\n",
    "        z = mu + eps * torch.sqrt(var)\n",
    "        return z\n",
    "            \n",
    "    def encode(self, x, training=True):\n",
    "        mu, var = self.encoder(x)\n",
    "        z = self.reparameterize(mu, var)\n",
    "        return (mu, var, z) if training else mu\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        mu_z, var_z, z = self.encode(x)\n",
    "        mu_x, var_x = self.decode(z)\n",
    "        return (mu_z, var_z), mu_x, var_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOPktsUCmhsL"
   },
   "outputs": [],
   "source": [
    "class MSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSELoss, self).__init__()\n",
    "        \n",
    "    def forward(self, mu, var, x):\n",
    "        prob = -0.5 * (torch.log(np.pi * 2 * var) + (x - mu) ** 2 / var)\n",
    "        loss = -prob.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrvA-gExmhsN"
   },
   "outputs": [],
   "source": [
    "class KLLossStandard(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KLLossStandard, self).__init__()\n",
    "        \n",
    "    def forward(self, mu, var):\n",
    "        kl_div = 1.0 + torch.log(var) - mu ** 2 - var\n",
    "        kl_div = -0.5 * kl_div\n",
    "        loss = kl_div.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJTRcl1cmhsP"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion_mse, criterion_kl,\n",
    "          optimizer, scheduler, epochs):\n",
    "    losses_mse_train = []\n",
    "    losses_kl_train = []\n",
    "    losses_train = []\n",
    "    losses_mse_val = []\n",
    "    losses_kl_val = []\n",
    "    losses_val = []\n",
    "    for i in trange(epochs):\n",
    "        losses_mse = []\n",
    "        losses_kl = []\n",
    "        losses = []\n",
    "        model.train()\n",
    "        for xs in train_data_loader:\n",
    "            xs = xs.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            z_data, mu_x, var_x = model(xs)\n",
    "            \n",
    "            loss_mse = criterion_mse(mu_x, var_x, xs)\n",
    "            loss_kl = criterion_kl(*z_data)\n",
    "            loss = loss_mse + loss_kl\n",
    "\n",
    "            losses_mse.append(loss_mse.item())\n",
    "            losses_kl.append(loss_kl.item())\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses_mse_train.append(np.array(losses_mse).mean())\n",
    "        losses_kl_train.append(np.array(losses_kl).mean())\n",
    "        losses_train.append(np.array(losses).mean())\n",
    "\n",
    "        losses_mse = []\n",
    "        losses_kl = []\n",
    "        losses = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for xs in val_data_loader:\n",
    "                xs = xs.to(device)\n",
    "\n",
    "                z_data, mu_x, var_x = model(xs)\n",
    "\n",
    "                loss_mse = criterion_mse(mu_x, var_x, xs)\n",
    "                loss_kl = criterion_kl(*z_data)\n",
    "                loss = loss_mse + loss_kl\n",
    "\n",
    "                losses_mse.append(loss_mse.item())\n",
    "                losses_kl.append(loss_kl.item())\n",
    "                losses.append(loss.item())\n",
    "\n",
    "        losses_mse_val.append(np.array(losses_mse).mean())\n",
    "        losses_kl_val.append(np.array(losses_kl).mean())\n",
    "        losses_val.append(np.array(losses).mean())\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    plt.plot(range(epochs), losses_mse_train, label=\"train\")\n",
    "    plt.plot(range(epochs), losses_mse_val, label=\"val\")\n",
    "    plt.xlabel('epoch num')\n",
    "    plt.ylabel('loss mse')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(epochs), losses_kl_train, label=\"train\")\n",
    "    plt.plot(range(epochs), losses_kl_val, label=\"val\")\n",
    "    plt.xlabel('epoch num')\n",
    "    plt.ylabel('loss KL')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(epochs), losses_train, label=\"train\")\n",
    "    plt.plot(range(epochs), losses_val, label=\"val\")\n",
    "    plt.xlabel('epoch num')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcnnLJhBmhsR"
   },
   "outputs": [],
   "source": [
    "def show_interpolation(model, n=5, m=10):\n",
    "    sample_ids = list(range(n))\n",
    "    samples_a = xs_train[sample_ids]\n",
    "    samples_b = xs_train[sample_ids[-1:] + sample_ids[:-1]]\n",
    "    samples_a = collate_fn(samples_a).to(device)\n",
    "    samples_b = collate_fn(samples_b).to(device)\n",
    "    \n",
    "    images = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(n):\n",
    "            a, b = samples_a[i], samples_b[i]\n",
    "            za, zb = model.encode(a[None, :], training=False), model.encode(b[None, :], training=False)\n",
    "            for j in range(m):\n",
    "                x, _ = model.decode(za + (zb - za) * j / (m - 1))\n",
    "                x = x.permute(0, 2, 3, 1).cpu().numpy()[0]\n",
    "                images.append(x)\n",
    "            \n",
    "    images = np.array(images)\n",
    "    images = (images + 1) / 2\n",
    "    images = np.clip(images, 0, 1)\n",
    "    \n",
    "    f, axarr = plt.subplots(n, m)\n",
    "    f.set_figheight(15)\n",
    "    f.set_figwidth(15)\n",
    "    for i, img in enumerate(images):\n",
    "        axarr[n - 1 - i // m, i % m].imshow(img)\n",
    "        axarr[n - 1 - i // m, i % m].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9FEm0nO9mhsT"
   },
   "outputs": [],
   "source": [
    "def show_sampels(model, n=100):\n",
    "    z = torch.randn([n, *model.get_latent_size()]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        images, _ = model.decode(z)\n",
    "        images = images.permute(0, 2, 3, 1).cpu().numpy()\n",
    "        \n",
    "    images = (images + 1) / 2\n",
    "    images = np.clip(images, 0, 1)\n",
    "    \n",
    "    n = int(np.ceil(np.sqrt(n)))\n",
    "    f, axarr = plt.subplots(n, n)\n",
    "    f.set_figheight(15)\n",
    "    f.set_figwidth(15)\n",
    "    for i, img in enumerate(images):\n",
    "        axarr[i // n, i % n].imshow(img)\n",
    "        axarr[i // n, i % n].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853,
     "referenced_widgets": [
      "41c64fb317804c3eb1be51c75efd9a32",
      "c267852776404ae796bccf343ab0d96f",
      "335ee2ef172f45ffafd8aac8b56551e3",
      "a8b186060b004e7ba57eeef5c534a76f",
      "ca9dfce88efb422f9d1e496e8d07b901",
      "160796588ec8401bb000fcb8ffcfcb8c",
      "84f26b3609d74ae69150135a78e67d90",
      "ceb874cf95ba4a6a808dc275f69cd767"
     ]
    },
    "colab_type": "code",
    "id": "gkfQcIe8mhsV",
    "outputId": "6f110224-3f45-4b2c-81e9-8095d11d3b2d"
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.0002\n",
    "w_l2 = 0\n",
    "\n",
    "model = VAE(channels=4)\n",
    "model.to(device)\n",
    "\n",
    "criterion_mse = MSELoss()\n",
    "criterion_kl = KLLossStandard()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr, weight_decay=w_l2)\n",
    "\n",
    "train(model, criterion_mse, criterion_kl, optimizer, None, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "id": "m81UYiaDmhsZ",
    "outputId": "c0c06970-52d3-4165-c18e-e3a08140347d"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "show_interpolation(model, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "id": "ZPzXVf3Ymhsc",
    "outputId": "4e166e12-8a99-4e92-a36a-ee63a4eee1af"
   },
   "outputs": [],
   "source": [
    "show_sampels(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWSW5251mhse"
   },
   "source": [
    "## Part B VAE PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.register_buffer('mask', torch.ones_like(self.weight))\n",
    "        _, _, h, w = self.mask.size()\n",
    "        self.mask[:, :, h // 2, w // 2 + (mask_type == 'B'):] = 0\n",
    "        self.mask[:, :, h // 2 + 1:] = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskResBlock(nn.Module):\n",
    "    def __init__(self, h=128):\n",
    "        super(MaskResBlock, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2 * h, h, 1),\n",
    "            nn.BatchNorm2d(h),\n",
    "            nn.ReLU(),\n",
    "            MaskedConv2d('B', h, h, 3, 1, 1),\n",
    "            nn.BatchNorm2d(h),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(h, 2 * h, 1),\n",
    "            nn.BatchNorm2d(2 * h)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x) + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module): # TODO\n",
    "    def __init__(self, h=128):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        \n",
    "        layers = [MaskedConv2d('A', h, 2 * h, 3, 1, 1)]\n",
    "        layers += [MaskResBlock(h) for _ in range(3)]\n",
    "        layers += [nn.Conv2d(2 * h, 2 * h, kernel_size=1)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.reshape(-1, 2, x.shape[1] // 2, 8, 8)\n",
    "        mu, log_var = x[:, 0], x[:, 1]\n",
    "        var = torch.exp(log_var)\n",
    "        return mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEPixelCNN(nn.Module):\n",
    "    def __init__(self, channels=64):\n",
    "        super(VAEPixelCNN, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        \n",
    "        self.encoder = Encoder(channels)\n",
    "        \n",
    "        self.pixel_cnn = PixelCNN(2 * channels)\n",
    "        \n",
    "        self.decoder = Decoder(channels)\n",
    "        \n",
    "    def get_latent_size(self):\n",
    "        return [2 * self.channels, 8, 8]\n",
    "    \n",
    "    def reparameterize(self, mu, var):\n",
    "        eps = torch.randn_like(mu, device=device)\n",
    "        z = mu + eps * torch.sqrt(var)\n",
    "        return z\n",
    "            \n",
    "    def encode(self, x, training=True):\n",
    "        mu_z1, var_z1 = self.encoder(x)\n",
    "        z1 = self.reparameterize(mu_z1, var_z1)\n",
    "        mu_z2, var_z2 = self.pixel_cnn(z1)\n",
    "        z2 = self.reparameterize(mu_z2, var_z2)\n",
    "        return (mu_z1, var_z1, z1, mu_z2, var_z2, z2) if training else mu_z2\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        mu_z1, var_z1, z1, mu_z2, var_z2, z2 = self.encode(x)\n",
    "        mu_x, var_x = self.decode(z2)\n",
    "        return (mu_z1, var_z1, z1, mu_z2, var_z2, z2), mu_x, var_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KLLoss, self).__init__()\n",
    "        \n",
    "    def get_prob(self, mu, var, x):\n",
    "        return -0.5 * (torch.log(np.pi * 2 * var) + (x - mu) ** 2 / var)\n",
    "        \n",
    "    def forward(self, mu_z1, var_z1, z1, mu_z2, var_z2, z2):\n",
    "        p1 = self.get_prob(mu_z1, var_z1, z1)\n",
    "        p2 = self.get_prob(mu_z2, var_z2, z2)\n",
    "        loss = (z1 - z2).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.0002\n",
    "w_l2 = 0\n",
    "\n",
    "model = VAEPixelCNN(channels=4)\n",
    "model.to(device)\n",
    "\n",
    "criterion_mse = MSELoss()\n",
    "criterion_kl = KLLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr, weight_decay=w_l2)\n",
    "\n",
    "train(model, criterion_mse, criterion_kl, optimizer, None, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "show_interpolation(model, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sampels(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "hw32.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "160796588ec8401bb000fcb8ffcfcb8c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "335ee2ef172f45ffafd8aac8b56551e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_160796588ec8401bb000fcb8ffcfcb8c",
      "max": 15,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca9dfce88efb422f9d1e496e8d07b901",
      "value": 15
     }
    },
    "41c64fb317804c3eb1be51c75efd9a32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_335ee2ef172f45ffafd8aac8b56551e3",
       "IPY_MODEL_a8b186060b004e7ba57eeef5c534a76f"
      ],
      "layout": "IPY_MODEL_c267852776404ae796bccf343ab0d96f"
     }
    },
    "84f26b3609d74ae69150135a78e67d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8b186060b004e7ba57eeef5c534a76f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ceb874cf95ba4a6a808dc275f69cd767",
      "placeholder": "​",
      "style": "IPY_MODEL_84f26b3609d74ae69150135a78e67d90",
      "value": "100% 15/15 [19:51&lt;00:00, 79.40s/it]"
     }
    },
    "c267852776404ae796bccf343ab0d96f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca9dfce88efb422f9d1e496e8d07b901": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ceb874cf95ba4a6a808dc275f69cd767": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
